{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cea8cc0c",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN) Fire Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52e888b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bened\\anaconda3\\envs\\tf_env\\lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import the Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07672486",
   "metadata": {},
   "source": [
    "# PART 1: Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3fba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Import the Keras Libraries and Packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd10834",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bened\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12544</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">802,880</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12544\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m802,880\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">826,497</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m826,497\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">826,497</span> (3.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m826,497\u001b[0m (3.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# B. Initializing the CNN\n",
    "classifier = Sequential()\n",
    "  \n",
    "# C. Creating the Convolutional Layer of the First Convolutional Block\n",
    "classifier.add(Conv2D(filters = 32, kernel_size = (3, 3), strides =  (1,1), input_shape = (64,64,3), activation = \"relu\"))\n",
    "\n",
    "# D. Creating the Pooling Layer of the First Convolutional Block\n",
    "classifier.add (MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# E. Creating the Convolutional Layer of the Second Convolutional Block\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (3, 3), strides =  (1,1), activation = \"relu\"))\n",
    "\n",
    "# F. Creating the Pooling Layer of the Second Convolutional Block\n",
    "classifier.add (MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# G. To Perform Flattening \n",
    "classifier.add(Flatten())\n",
    "\n",
    "# H. Creating the Fully Connected Layer\n",
    " \n",
    "# H.1 For the First Hidden Layer \n",
    "classifier.add(Dense(units = 64, kernel_initializer = \"glorot_uniform\", activation = \"relu\"))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# H.2 For the Second Hidden Layer \n",
    "classifier.add(Dense(units = 64, kernel_initializer = \"glorot_uniform\", activation = \"relu\"))\n",
    "classifier.add(Dropout(rate = 0.1))\n",
    "\n",
    "# H.3 For the Output Layer \n",
    "classifier.add(Dense(units = 1, kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\"))\n",
    "\n",
    "# I. Compiling the CNN\n",
    "classifier.compile(optimizer = \"sgd\", loss = \"binary_crossentropy\", metrics = [\"accuracy\", \"mse\"])\n",
    "\n",
    "print(classifier.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c894fbc",
   "metadata": {},
   "source": [
    "# PART 2: Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0d30b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Test', 'Train', 'Vali']\n",
      "The Number of Samples for the Training Data Fire Category:\n",
      "3003\n",
      "The Number of Samples for the Training Data Non-Fire Category:\n",
      "3000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPv9JREFUeJzt3QncjPX+//GPfQ0hW8mSyhIqOtKiRCQtSufkJJSlONRBh47fkaRFKVQiOSVtik5poeylE4qUiCgdDmVNWYvbcv0f7+/vd81/Zty3+76573vG/X09H49xm5lrrrnm2uZ9fbfJEwRBYAAAAB7Lm+gFAAAASDQCEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQJRLjB48GDLkydPjrzX5Zdf7m6hjz/+2L33v/71rxx5/9tuu82qVq1qyWzPnj3WtWtXq1Chgls3vXv3PuZt+vPPP9uJ7ni2WU7u27mB1vM111xjJ5LwHKK/6Vm8eLFddNFFVqxYMfeapUuX5sgywg8EoiQzYcIEd6CHt8KFC1ulSpWsZcuW9vTTT9vu3buz5H02btzovmyS8YSSzMuWEY888ojbjj169LBXXnnFOnTocNRp33nnHUuE6P3saLeMfFHlRgpy0euhePHiVr16dbvpppvsrbfessOHDx/zvCdOnGhPPvlkli5vbnfgwAH74x//aL/88ouNHDnSHVtVqlSxZPfDDz/YnXfe6fYdnc9LlChhF198sT311FP2+++/Z3p+Y8aMcecXZL382TBPZIEhQ4ZYtWrV3Elg8+bN7ktJJQ0jRoyw9957z+rVqxeZduDAgfb3v/8906HjgQcecFeU5557boZfN3PmTMtuR1u2f/7zn8f1RZQT5s6daxdeeKHdf//96U6rQKQv2DZt2lhO0xdKtJdfftlmzZp1xOO1atU6rvc5nm12LPt2VipUqJA9//zz7v/68vrvf/9r77//vttmKil999133RfcsQSib7755phKD32lYKH1r/1JJbAngmnTprkQp/2oY8eOds4551hKSop9+umn1q9fP1uxYoWNGzcu04GobNmyLrAjaxGIklSrVq2sYcOGkfsDBgxwX7QqDr/uuuvs22+/tSJFirjn8ufP727Z6bfffrOiRYtawYIFLZEKFChgyW7r1q1Wu3ZtS3a33nprzP3PPvvMBaL4x9PaF3Jim+XEvp3e+8evj4ceesgeffRRd0x269bNJk2alLDl84mOKylVqlS60+7du9dVqyXS2rVrrV27dq4US+fuihUrRp7r2bOnrVmzxgWm3GpvEmyDTNOv3SN5vPjii4E2y+LFi1N9/pFHHnHPjxs3LvLY/fff7x6LNnPmzODiiy8OSpYsGRQrViw466yzggEDBrjnPvroIzd9/E3vLZdddllQp06d4IsvvgguvfTSoEiRIsFf//rXyHO6hcJ5vfHGG27+5cuXD4oWLRpce+21wfr162OWqUqVKkGnTp2O+EzR80xv2fR6zSfanj17gr59+wannXZaULBgQfdZH3/88eDw4cMx02k+PXv2DKZMmeI+n6atXbt28OGHH2Zo22zZsiXo3LlzUK5cuaBQoUJBvXr1ggkTJhyxLuJva9euTXV+qU0brp9wm37//ffuMW3HEiVKBLfddluwd+/eI+b1yiuvBOeff35QuHDh4OSTTw5uvvnmI9Z/erRu4vejo+0L77zzTnD11VcHFStWdOuyevXqwZAhQ4KDBw/GzCN+m2l96H20jZ577jn3Or2+YcOGwaJFi2Jem9q+nZntqG3SoEEDt730PmPHjk11nqnRcuvYSUuLFi2CPHnyBKtXr448lpF1onUav93D9bN///7gvvvuc9tS21vH0iWXXBLMnTs3yAjNp3Xr1sGMGTOC+vXru89dq1at4K233oqZbvv27cE999wTnHPOOe4znnTSScFVV10VLF269Ih5Pv300279atuXKlXKrc/XXnstZpoff/wxuP32292xEW6PF1544Yh5bdiwIbj++uvd5zrllFOC3r17B9OnT3frQNvqaNsifp2F54xwO61ZsyZo1apVULx4cfcex3JumDx5sltfOo4uvPDCYNmyZe557TdnnHGGW59637SO6Wjdu3d3850/f36QEePHjw+aNm3q1ouWVcsxZsyYI7ZvWutBfv31V3d8hp9Xy/zoo48Ghw4dipnPzz//HNx6661uu+vc0rFjR7fto8+1oTlz5rh9UNtM01533XXBypUrY6YJj6kVK1YEf/7zn91+cu6557rPpMe//PLLIz7vww8/HOTNm9ftO8mCEqITjNqj/M///I+rutLVaWpUDKuSJFWrqepNxbW6Gpk/f36kCkSPDxo0yO644w679NJL3eNqrBjavn27K6XSFY6ukMuXL3/U5Xr44YddO4t7773XXcmpfUTz5s1dO6CwJCsjMrJs0XQuU4nZRx99ZF26dHFVbDNmzHDF0T/99JNraxBNRdVvv/22/eUvf7GTTjrJtctq27atrV+/3sqUKZPmcqm6RFUkWo+9evVy1ZlvvvmmK7besWOH/fWvf3XLruqmPn362GmnnWb33HOPe+0pp5yS6jw1rYr+//CHP7jPKmeccUbMNH/605/cew0dOtS+/PJLV31Trlw5e+yxx2LW/X333eem1fy2bdtmo0aNsiZNmthXX32VoSvqo0lrX1A7BrWr6du3r/urq2Btt127dtnjjz+eoWojtYlT+wrtO8OGDbMbb7zR/vOf/6RbqpSR7ajPftVVV7krc1XBHjp0yO1baW2PYzkWdRyqVO2ss87K8Dr5xz/+YTt37rQff/wxsn9qWtF02sZ//vOf3fGt9fPCCy+4NoSLFi3KUPX2999/bzfffLN1797dOnXqZC+++KKrtpk+fbpdeeWVbhqtY7Vd0+Pav7Zs2WLPPfecXXbZZbZy5UrXblFUPXX33Xe7KkLt4/v27bNly5bZ559/brfccoubRq9VFbG2oY4Nrd8PP/zQHY/6PGG1oI6hZs2auW2keeo9dAxoHaVH+8ipp57qqpj12gsuuCDmnHTw4EG3ji655BJ74oknXAlmZs8N//73v11zBJXeiI45nUf79+/vqqm0r/36669uP+3cuXO6y62qVbUbSuvcFe/ZZ5+1OnXquGVWyaRer/dUdXO4TDqv3nXXXW5/0X4k4XpQya22nz6b1tfpp59uCxYscCWZmzZtirRZ0/yuvfZatz+pnWPNmjVd1W+nTp2OWKbZs2e7Y1+fQ+06tQ11blEbKJ2P4jtLaH8688wz3XbS+td+o2V/7bXX7LzzzouZVo/pnKrtmjQSnciQuRIiUUo/77zzIvfjr3hHjhzp7m/bti3NeWj+qV0NRF/B6qootedSKyE69dRTg127dkUe15WWHn/qqacyVUKU3rLFlzboilzTPvTQQzHT3XTTTe7qXVeNIU2nq6box77++mv3+KhRo4KjefLJJ910r776auSxlJSUoHHjxu6KNPqzh1fpGaEr29TWSbhNVSIV7YYbbgjKlCkTub9u3bogX7587mor2vLly4P8+fMf8fixlBCltS/89ttvRzx25513uivJffv2pVtCpM/xyy+/RB5/99133ePvv//+EeshWka3o0optSw//fRT5DGVuGm9ZEUJ0VdffeXm06dPn0yvE+0f8SWdopIklRJF01W/Sl7j94XUhCUI0SVCO3fudCVW0ecMLUt8qYG2i0pAVKIVUkmLSuGOpkuXLm7+KnWI1q5dO3euCtdJeAzp3BBSaWeNGjXSLSGKPte8+eabqZYe/f3vf495PLPnBn326JIflV7q8QoVKsQc3yoJP1rJb7jONU1YUpURqe07LVu2dKWM0bQ9os+XoQcffNDtr999913M41ovOkeEJcbaN7Rs2h4h7QtXXHHFEeddlfKo1E8litHHmkp2VKoUf5yqdCieHqtUqVLM/qYSo7TO8YlEL7MTkK4OjtbbLCwRUOo/1sasKlW6/fbbMzy9GgzqSj2kKwNdmX/wwQeWnTT/fPnyuavGaCqd0XlOV6rRVGoVXQqjUjQ1itUVc3rvo270unIPqRRD76tu9vPmzbPsoKv8aCoxU4mNrrxFpSTaxiodUhf98KZl1ZWaro6PV1r7QnTJn/ZHva+WT1eqq1atSne+KsU4+eSTYz6bpLctMrIdVRqkq1s1Vg9LO6RGjRruijcrhKU60cfi8a4T7cthOz1tV/WoUumH2hPqijwj9HlvuOGGyH2tFx2fKjFTB41wm+bNmzeyrrRP6fOcffbZMe+jc4lKstTdPTU6xtTjTiUO+n/0PqgSG5WEhfPTMaRzgs4NIZXkhKWjx0ulHcdzblDpVXSJR6NGjdxflTxGn9vCx4+2n4bHZ/Tr0hO972i9aR2qxEfvo/vpUYm19jUdU9HbQceKtvEnn3ziplNJoc5d0TUM2hd6/l8pVEilSirhVyl46dKlY441lTSmdm6PP1+J9j11lIk+F6l0SJ9X6zaZEIhOQPoCPtqBpi8aFWmq+kTFqarqmDx5cqbCkYoxM9OAWl++0VR8ri+fdevWWXZSrxN9AcSvj7BnlJ6PpmLkeDqBqCg8vffRZwy/RNJ7n6wSv7xhgAiXV9UjOrlr2VRVEX1Tw/uwIerxSGtfUNWsvnhLlizpvnT1nmED5IycwNP7bJl5bfj68LX63Cre1z4YL7XHjvU4lOh973jXibz00kvuS0ddtFX9p3mo8W1GX6/PFz92U1ilFx6POheoykj7jcKRei3pfVQdFv0+qgJXUFK1rqbVl2ZY9S6qnlWVsXpKxe9/YYgO90EdI6ktm0LY8VIVk6qps/LcoG0olStXTvXxo+2nYc/DzAyTovWq8KKGyAqiWodqHiEZ2fY6FyjsxG8HzTN+OyiYxneMqBF3XITrJ7Xto3WosKWG09FU/RpP4UnvpxAU7nuvv/66XX/99ZkKjDmBNkQnGF2t6eA42kldyVtXA0rkOpHqIFFPmCuuuMK1edBVU3oy0+4no9IaYE9XLxlZpqyQ1vv8b6l58klveXVy0XrV1W5q04alGMcjtX1BX4K6etWJX+1yVFqjL3CVBuhLNCPh+3i2RTJsR3Wbl/BYzIp18uqrr7orcpVsqa2L2ovps6o9i7qdZxW18VC7M7WFefDBB10JgMK+2vtEL6e++FavXm1Tp0515xGVBqk9jdpFqV1WOK1CX2ptUCR6iJDsEl3idazS2qeOZV/TPqAwFu4j6dG2VQmV2vNoaBWFMF2EqBRGwTUj+46mUfhQm6fUhKE4OxVJ5Vyh9af2ZmqPpn1HwU8lRun1Zk0EAtEJJhwjRsXRR6OTgw4w3XSA6QSoRngKSbpiyOrRf3V1En+yUAPk6JOhruD1pRFPVyJqtBfKzLKpS6uqRnQlFn21EVZPZNXAbZqPrp510ok+8R7v+xzvdtCXrta1rsxy4oQX0rhYqmZRlZ0ab0d3NU4GChIKI9oH46X22LEei9p+YUPlzKyTtLa7RnzXsaB5RE+TkTGtoj+f9ono13/33Xfub1glpPdp2rSpa7AdTcenSouiqcRCpc66aQwdNXxXQ3411lUJhI47XdSEJRFp0TGigBC/bApc2SGnzg1pUYNslZwtXLjQGjdufNRp1YB6//79rlF3dElValXeae07Oheo1DIj20HzjR8+Y03ccRGun9S2j9ah9pOMdqtXtdnw4cPd59TFm/ab9L7DEoEqsxOIejXoak5ffu3bt09zOrU7iBf2TtFBJ+GOnFpAORYa1C+6eFgnXNVBR7fX0AGrsW50Ug3pynPDhg0x88rMsl199dXuZPzMM8/EPK6rKp04sqq9iN5H7S+ix5xR2w71uFApjEoGjoU+6/FsA3056QpMV+vxV6y6ry/o7BBeNUe/p7arrgCTgZZPXwzqSaWr0eiTfnzbkWOhcYhU2qqQEFYXZ2adaLunVg2S2jzUo0tfqhmlzztlypSY9iw6PnUOUNuy8H3i9xe1QVEPpWjx+49KLTTGll6rQWM1H7UDUclRaqUhqlKLPoa0bNE/86Mv5cwOTJhROXVuSItKarSd1XRBPfFSKxXSaNVpbXftH+ohmNFzhtoRaj9RT7p4ml7nK1EQ0bZTiU1IF3qjR4+OeY2qubTPqAo3+v20nbXva/1mlC6MdVMPSu0rasaRyPHF0pJ8SwRHJ22lcO3EOpgUhtS9V6ldVxG6+k2LiutVZda6dWs3veqOdVJWHbu6pYbhRPXUY8eOdVdPOsjUWDC1OuCMUJG75q12A1pedfFUVUJ0wz2dGHQyVFdoHbw6IaiKIL6reWaWTY05daWr0i+1j6hfv747WNWgXMX/8fM+Vmr4qW7Jqs5YsmSJu9LWZ1Hxrz7rsdaFN2jQwF3FqhRPRez6jGGjzYzQ59NAgbpa1+dXVYuWRaUS+lLUcv/tb3+zrKauxCrxUzWJGq3qC0YlJslU9ahuwtoX1J5ODW7DL0eNFpzRn4XR8ad9VNTlXKWZOv5UWqj9LvrLPDPrRNtd4Vrd89WFXKFa+7JKFVQ6pHZIOn61HXUcKISEbZbSo5JCdTNXQ2i1IRw/frw7JqO/XPU+Ok/oeNVyL1++3LXxiC6plRYtWrgQpXWoealdmtahli3c5xUOVeKg/VbHu5ZVF2WqKtS+HV6g6Tm9VqUFOob0hav1k5lBPjMjp84NadH8NbSEQrOqHqNHqlZ3+HDYjnA9K2xqmdVlXttagUUlnbqwjN931EVfx73OsZpGzSFUxap9U9tW89V0auOjbatzldaBSnV0jlCbMDUu1wWCqun0ul/+bztFl0BpqAgFR5VwaZ8Ku92rHZWOr8zQ5w/PRclYXeYkupsbUu92H97UvVjdPq+88krXhT26+2daXZM1kJa6e6qro16vv+r6GN8dU92cNYBa2A05fmDG1KTV7f7111933VHVRVMDuKlb8X//+98jXj98+HDXRV9dXDVwpAb8i5/n0ZYttYEZd+/e7bo+63MWKFAgOPPMM486+Fq8tIYDSG1gRg0+V7ZsWbde69atm2q30cx0u1+1alXQpEkTt85SG5gxfuiEcP+I7/KrrrQaPE3dbnWrWbOm+6zRgwYez8CMqdGAcxq8Tsuudd+/f383IGB8F+qjDcwYT4/rs2dkYMaMbEcdC+puHg5S9/zzz7sBCTXwXnriBwNU1/mqVasGbdu2Df71r38d0W09M+tEAwbecsstbgC76IEZtc9q8FXd1zGiZZ86dWqq+316AzNq4FDNQ/tCfFd1dbvXelB3eS2rjsWFCxcecSyq67n2Tw2RoHlpHfbr1891K48/NrRNKleu7I5BnbOaNWsWM4Cs6Jyggf20LnUcaRDBjAzMmF63+7SGRziec0Na+2lay5EWnXe7devm9h3thxoMUetbQ0RED8Xw3nvvuW2mfVPTPvbYY5GBDaOP982bN7ttrPnED8yoz6vzsIYy0HtpHV900UXBE0884YYJCem8ov0vHJhRA77Onz8/MshutNmzZ7vl1X6iwUI1nEVaAzMebaiXTZs2ue7/GhwzWeXRP4kOZQCQU3SFrN5g8e3eAJ+98847rmRSg56qRDCrqVeaSgXVIF8N+pMRbYgA5FrxvyauEKSeOxohF/BV/HGh6uRRo0a53nHnn39+trynRnHX+2iE92RFGyIAuZbaxKg9hf6q/Y/aXqitRlpdkwEf6Oc/FIrUNkgdbdRubcGCBa43clYPuaL2r/o5GPVMVOls/M99JBOqzADkWmo0rAa/6iGosWr0BaCTfnZdBQMnAjX2Vjd4NapWZwE1zu7Ro4f7LbqsptJYhS1Vw6mDQlL9dlkcAhEAAPAebYgAAID3CEQAAMB7NKrOAI3iqRFWNRBZVv/kBQAAyB5qFaRfUdDAt+n93h2BKAMUhuJ/8RgAAJwY9BNR+rWGoyEQZUA4RL1WqMZpAAAAyU+/5acCjYz8vBKBKAPCajKFIQIRAAAnlow0d6FRNQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8l9BA9Oyzz1q9evUivxHWuHFj+/DDDyPP79u3z3r27GllypSx4sWLW9u2bW3Lli0x81i/fr21bt3aihYtauXKlbN+/frZwYMHY6b5+OOP7fzzz7dChQpZjRo1bMKECTn2GQEAQPJLaCA67bTT7NFHH7UlS5bYF198YVdccYVdf/31tmLFCvd8nz597P3337c333zT5s2bZxs3brQbb7wx8vpDhw65MJSSkmILFiywl156yYWdQYMGRaZZu3atm6Zp06a2dOlS6927t3Xt2tVmzJiRkM8MAACST54gCAJLIqVLl7bHH3/cbrrpJjvllFNs4sSJ7v+yatUqq1Wrli1cuNAuvPBCV5p0zTXXuKBUvnx5N83YsWPt3nvvtW3btlnBggXd/6dNm2bffPNN5D3atWtnO3bssOnTp2domXbt2mUlS5a0nTt38mv3AACcIDLz/Z00bYhU2vPGG2/Y3r17XdWZSo0OHDhgzZs3j0xTs2ZNO/30010gEv2tW7duJAxJy5Yt3QoIS5k0TfQ8wmnCeaRm//79bh7RNwAAkHvlT/QCLF++3AUgtRdSO6EpU6ZY7dq1XfWWSnhKlSoVM73Cz+bNm93/9Tc6DIXPh88dbRqFnN9//92KFClyxDINHTrUHnjgAcspVf8+LcfeCzjRrHu0teUGHOdAch/rCS8hOvvss134+fzzz61Hjx7WqVMnW7lyZUKXacCAAa54Lbxt2LAhocsDAAByeQmRSoHU80saNGhgixcvtqeeespuvvlm11habX2iS4nUy6xChQru//q7aNGimPmFvdCip4nvmab7qktMrXRI1BtNNwAA4IeElxDFO3z4sGvDo3BUoEABmzNnTuS51atXu272qmIT/VWV29atWyPTzJo1y4UdVbuF00TPI5wmnAcAAED+RFdNtWrVyjWU3r17t+tRpjGD1CVercK7dOliffv2dT3PFHLuuusuF2TUw0xatGjhgk+HDh1s2LBhrr3QwIED3dhFYQlP9+7d7ZlnnrH+/ftb586dbe7cuTZ58mTX8wwAACDhgUglOx07drRNmza5AKRBGhWGrrzySvf8yJEjLW/evG5ARpUaqXfYmDFjIq/Ply+fTZ061bU9UlAqVqyYa4M0ZMiQyDTVqlVz4UdjGqkqTmMfPf/8825eAAAASTkOUTLK7nGI6H0CJG/Pk6zCcQ7k/LF+Qo5DBAAAkCgEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8lNBANHTrULrjgAjvppJOsXLly1qZNG1u9enXMNJdffrnlyZMn5ta9e/eYadavX2+tW7e2okWLuvn069fPDh48GDPNxx9/bOeff74VKlTIatSoYRMmTMiRzwgAAJJfQgPRvHnzrGfPnvbZZ5/ZrFmz7MCBA9aiRQvbu3dvzHTdunWzTZs2RW7Dhg2LPHfo0CEXhlJSUmzBggX20ksvubAzaNCgyDRr16510zRt2tSWLl1qvXv3tq5du9qMGTNy9PMCAIDklD+Rbz59+vSY+woyKuFZsmSJNWnSJPK4Sn4qVKiQ6jxmzpxpK1eutNmzZ1v58uXt3HPPtQcffNDuvfdeGzx4sBUsWNDGjh1r1apVs+HDh7vX1KpVyz799FMbOXKktWzZMps/JQAASHZJ1YZo586d7m/p0qVjHn/ttdesbNmyds4559iAAQPst99+izy3cOFCq1u3rgtDIYWcXbt22YoVKyLTNG/ePGaemkaPAwAAJLSEKNrhw4ddVdbFF1/sgk/olltusSpVqlilSpVs2bJlruRH7Yzefvtt9/zmzZtjwpCE9/Xc0aZRaPr999+tSJEiMc/t37/f3UKaDgAA5F5JE4jUluibb75xVVnR7rjjjsj/VRJUsWJFa9asmf3www92xhlnZFtj7wceeCBb5g0AAJJPUlSZ9erVy6ZOnWofffSRnXbaaUedtlGjRu7vmjVr3F+1LdqyZUvMNOH9sN1RWtOUKFHiiNIhUbWcqu/C24YNG47zEwIAgGSW0EAUBIELQ1OmTLG5c+e6hs/pUS8xUUmRNG7c2JYvX25bt26NTKMeawo7tWvXjkwzZ86cmPloGj2eGnXN1+ujbwAAIPfKm+hqsldffdUmTpzoxiJSWx/d1K5HVC2mHmPqdbZu3Tp77733rGPHjq4HWr169dw06qav4NOhQwf7+uuvXVf6gQMHunkr2IjGLfrPf/5j/fv3t1WrVtmYMWNs8uTJ1qdPn0R+fAAAkCQSGoieffZZVyWlwRdV4hPeJk2a5J5Xl3l1p1foqVmzpt1zzz3Wtm1be//99yPzyJcvn6tu01+V+Nx6660uNA0ZMiQyjUqepk2b5kqF6tev77rfP//883S5BwAAiW9UrSqzo6lcubIbvDE96oX2wQcfHHUaha6vvvoq08sIAAByv6RoVA0AAJBIBCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3EhqIhg4dahdccIGddNJJVq5cOWvTpo2tXr06Zpp9+/ZZz549rUyZMla8eHFr27atbdmyJWaa9evXW+vWra1o0aJuPv369bODBw/GTPPxxx/b+eefb4UKFbIaNWrYhAkTcuQzAgCA5JfQQDRv3jwXdj777DObNWuWHThwwFq0aGF79+6NTNOnTx97//337c0333TTb9y40W688cbI84cOHXJhKCUlxRYsWGAvvfSSCzuDBg2KTLN27Vo3TdOmTW3p0qXWu3dv69q1q82YMSPHPzMAAEg+eYIgCCxJbNu2zZXwKPg0adLEdu7caaeccopNnDjRbrrpJjfNqlWrrFatWrZw4UK78MIL7cMPP7RrrrnGBaXy5cu7acaOHWv33nuvm1/BggXd/6dNm2bffPNN5L3atWtnO3bssOnTp6e7XLt27bKSJUu65SlRokSWf+6qf5+W5fMEcot1j7a23IDjHMj5Yz0z399J1YZICyylS5d2f5csWeJKjZo3bx6ZpmbNmnb66ae7QCT6W7du3UgYkpYtW7qVsGLFisg00fMIpwnnEW///v3u9dE3AACQeyVNIDp8+LCryrr44ovtnHPOcY9t3rzZlfCUKlUqZlqFHz0XThMdhsLnw+eONo2Czu+//55q2yYlyvBWuXLlLP60AAAgmSRNIFJbIlVpvfHGG4leFBswYIArrQpvGzZsSPQiAQCAbJTfkkCvXr1s6tSp9sknn9hpp50WebxChQqusbTa+kSXEqmXmZ4Lp1m0aFHM/MJeaNHTxPdM033VJxYpUuSI5VFPNN0AAIAfElpCpPbcCkNTpkyxuXPnWrVq1WKeb9CggRUoUMDmzJkTeUzd8tXNvnHjxu6+/i5fvty2bt0amUY91hR2ateuHZkmeh7hNOE8AACA3/InuppMPcjeffddNxZR2OZH7XZUcqO/Xbp0sb59+7qG1go5d911lwsy6mEm6qav4NOhQwcbNmyYm8fAgQPdvMNSnu7du9szzzxj/fv3t86dO7vwNXnyZNfzDAAAIKElRM8++6xro3P55ZdbxYoVI7dJkyZFphk5cqTrVq8BGdUVX9Vfb7/9duT5fPnyueo2/VVQuvXWW61jx442ZMiQyDQqeVL4UalQ/fr1bfjw4fb888+7nmYAAABJNQ5RsmIcIiBxGIcI8MM6xiECAABILAIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgvWMKRNWrV7ft27cf8fiOHTvccwAAALk+EK1bt84OHTp0xOP79++3n376KSuWCwAAIMfkz8zE7733XuT/M2bMsJIlS0buKyDNmTPHqlatmrVLCAAAkEyBqE2bNu5vnjx5rFOnTjHPFShQwIWh4cOHZ+0SAgAAJFMgOnz4sPtbrVo1W7x4sZUtWza7lgsAACA5A1Fo7dq1Wb8kAAAAJ1IgErUX0m3r1q2RkqPQ+PHjs2LZAAAAkjcQPfDAAzZkyBBr2LChVaxY0bUpAgAA8CoQjR071iZMmGAdOnTI+iUCAAA4EcYhSklJsYsuuijrlwYAAOBECURdu3a1iRMnZv3SAAAAnChVZvv27bNx48bZ7NmzrV69em4MomgjRozIquUDAABIzkC0bNkyO/fcc93/v/nmm5jnaGANAAC8CEQfffRR1i8JAADAidSGCAAAwHwvIWratOlRq8bmzp17PMsEAACQ/IEobD8UOnDggC1dutS1J4r/0VcAAIBcGYhGjhyZ6uODBw+2PXv2HO8yAQAAnLhtiG699VZ+xwwAAPgdiBYuXGiFCxfOylkCAAAkZ5XZjTfeGHM/CALbtGmTffHFF3bfffdl1bIBAAAkbyAqWbJkzP28efPa2WefbUOGDLEWLVpk1bIBAAAkbyB68cUXs35JAAAATsQ2REuWLLFXX33V3b766qtMv/6TTz6xa6+91ipVquTGNXrnnXdinr/tttvc49G3q666KmaaX375xdq3b28lSpSwUqVKWZcuXY7o6aafGrn00ktd+6bKlSvbsGHDjvETAwCA3OiYSoi2bt1q7dq1s48//tiFENmxY4cbsPGNN96wU045JUPz2bt3r9WvX986d+58RLukkAJQdIlUoUKFYp5XGFL7pVmzZrnxkG6//Xa74447bOLEie75Xbt2uWq85s2b29ixY2358uXu/bTcmg4AAOCYAtFdd91lu3fvthUrVlitWrXcYytXrnSDMt599932+uuvZ2g+rVq1crejUQCqUKFCqs99++23Nn36dFu8eLE1bNjQPTZq1Ci7+uqr7YknnnAlT6+99pqlpKS44QAKFixoderUcYNIjhgxgkAEAACOvcpMIWTMmDGRMCS1a9e20aNH24cffmhZSaVQ5cqVc422e/ToYdu3b4/p5q+SnjAMiUqC1Mj7888/j0zTpEkTF4ZCLVu2tNWrV9uvv/6a6nvu37/flSxF3wAAQO51TIHo8OHDVqBAgSMe12N6Lquouuzll1+2OXPm2GOPPWbz5s1zJUqHDh1yz2/evNmFpWj58+e30qVLu+fCacqXLx8zTXg/nCbe0KFDXU+68KZ2RwAAIPc6pkB0xRVX2F//+lfbuHFj5LGffvrJ+vTpY82aNcuyhVM7peuuu87q1q1rbdq0salTp7rqMZUaZacBAwbYzp07I7cNGzZk6/sBAIATMBA988wzrhqpatWqdsYZZ7hbtWrV3GNqw5NdqlevbmXLlrU1a9a4+2pbpAbe0Q4ePOh6noXtjvR3y5YtMdOE99Nqm6R2S+q1Fn0DAAC51zE1qlYV0pdffmmzZ8+2VatWucfUnkjtd7LTjz/+6NoQVaxY0d1v3Lix692m7v8NGjRwj82dO9dV2zVq1CgyzT/+8Q/XAy2s5lOPNLVJOvnkk7N1eQEAQC4sIVLYUONplQRpTKArr7zS9TjT7YILLnA9uP79739neH4aL0g9vnSTtWvXuv+vX7/ePdevXz/77LPPbN26da4d0fXXX281atRwjaLDEKZ2Rt26dbNFixbZ/PnzrVevXq6qTT3M5JZbbnENqjU+kXrFTZo0yZ566inr27dv5tYUAADItTIViJ588kkXPlKrQlLj4zvvvNN1Z88o/fbZeeed526ikKL/Dxo0yPLly+cGVFQborPOOssFGpUCKXBFj0WkbvU1a9Z0bZfU3f6SSy6xcePGxSzXzJkzXdjS6++55x43f7rcAwCAY6oy+/rrr11vr7RoAESN/5NRl19+ufth2LTMmDEj3XmoR1k4CGNa6tWrl6mSKwAA4JdMlRCpMXJq3e2ju7xv27YtK5YLAAAgOQPRqaeeat98802az6uKK2zwDAAAkCsDkdro3HfffbZv374jnvv999/t/vvvt2uuuSYrlw8AACC52hANHDjQ3n77bdfIWb251HVd1PVeP9uhEaTVxR0AACDXBiL95MWCBQvcb4ppNOewQbS64KsrvEJR/M9kAAAA5LqBGatUqWIffPCB+2FUjRitUHTmmWcyyCEAAPBrpGpRANJgjAAAAF7+lhkAAEBuQiACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeC+hgeiTTz6xa6+91ipVqmR58uSxd955J+b5IAhs0KBBVrFiRStSpIg1b97cvv/++5hpfvnlF2vfvr2VKFHCSpUqZV26dLE9e/bETLNs2TK79NJLrXDhwla5cmUbNmxYjnw+AABwYkhoINq7d6/Vr1/fRo8enerzCi5PP/20jR071j7//HMrVqyYtWzZ0vbt2xeZRmFoxYoVNmvWLJs6daoLWXfccUfk+V27dlmLFi2sSpUqtmTJEnv88cdt8ODBNm7cuBz5jAAAIPnlT+Sbt2rVyt1So9KhJ5980gYOHGjXX3+9e+zll1+28uXLu5Kkdu3a2bfffmvTp0+3xYsXW8OGDd00o0aNsquvvtqeeOIJV/L02muvWUpKio0fP94KFixoderUsaVLl9qIESNighMAAPBX0rYhWrt2rW3evNlVk4VKlixpjRo1soULF7r7+qtqsjAMiabPmzevK1EKp2nSpIkLQyGVMq1evdp+/fXXHP1MAAAgOSW0hOhoFIZEJULRdD98Tn/LlSsX83z+/PmtdOnSMdNUq1btiHmEz5188slHvPf+/fvdLbraDQAA5F5JW0KUSEOHDnWlUeFNDbEBAEDulbSBqEKFCu7vli1bYh7X/fA5/d26dWvM8wcPHnQ9z6KnSW0e0e8Rb8CAAbZz587IbcOGDVn4yQAAQLJJ2kCkai4Fljlz5sRUXaltUOPGjd19/d2xY4frPRaaO3euHT582LU1CqdRz7MDBw5EplGPtLPPPjvV6jIpVKiQ68YffQMAALlXQgORxgtSjy/dwobU+v/69evduES9e/e2hx56yN577z1bvny5dezY0fUca9OmjZu+Vq1adtVVV1m3bt1s0aJFNn/+fOvVq5frgabp5JZbbnENqjU+kbrnT5o0yZ566inr27dvIj86AABIIgltVP3FF19Y06ZNI/fDkNKpUyebMGGC9e/f341VpO7xKgm65JJLXDd7DbAYUrd6haBmzZq53mVt27Z1YxeF1AZo5syZ1rNnT2vQoIGVLVvWDfZIl3sAABDKE2jAHxyVquoUrNSeKDuqz6r+fVqWzxPILdY92tpyA45zIOeP9cx8fydtGyIAAICcQiACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4L6kD0eDBgy1Pnjwxt5o1a0ae37dvn/Xs2dPKlCljxYsXt7Zt29qWLVti5rF+/Xpr3bq1FS1a1MqVK2f9+vWzgwcPJuDTAACAZJXfklydOnVs9uzZkfv58///Re7Tp49NmzbN3nzzTStZsqT16tXLbrzxRps/f757/tChQy4MVahQwRYsWGCbNm2yjh07WoECBeyRRx5JyOcBAADJJ+kDkQKQAk28nTt32gsvvGATJ060K664wj324osvWq1ateyzzz6zCy+80GbOnGkrV650gap8+fJ27rnn2oMPPmj33nuvK30qWLBgAj4RAABINkldZSbff/+9VapUyapXr27t27d3VWCyZMkSO3DggDVv3jwyrarTTj/9dFu4cKG7r79169Z1YSjUsmVL27Vrl61YsSLN99y/f7+bJvoGAAByr6QORI0aNbIJEybY9OnT7dlnn7W1a9fapZdeart377bNmze7Ep5SpUrFvEbhR8+J/kaHofD58Lm0DB061FXBhbfKlStny+cDAADJIamrzFq1ahX5f7169VxAqlKlik2ePNmKFCmSbe87YMAA69u3b+S+SogIRQAA5F5JXUIUT6VBZ511lq1Zs8a1K0pJSbEdO3bETKNeZmGbI/2N73UW3k+tXVKoUKFCVqJEiZgbAADIvU6oQLRnzx774YcfrGLFitagQQPXW2zOnDmR51evXu3aGDVu3Njd19/ly5fb1q1bI9PMmjXLBZzatWsn5DMAAIDkk9RVZn/729/s2muvddVkGzdutPvvv9/y5ctnf/7zn13bni5duriqrdKlS7uQc9ddd7kQpB5m0qJFCxd8OnToYMOGDXPthgYOHOjGLlIpEAAAQNIHoh9//NGFn+3bt9spp5xil1xyietSr//LyJEjLW/evG5ARvUMUw+yMWPGRF6v8DR16lTr0aOHC0rFihWzTp062ZAhQxL4qQAAQLJJ6kD0xhtvHPX5woUL2+jRo90tLSpd+uCDD7Jh6QAAQG5xQrUhAgAAyA4EIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABAAAvEcgAgAA3iMQAQAA7xGIAACA9whEAADAewQiAADgPQIRAADwHoEIAAB4j0AEAAC8RyACAADeIxABAADvEYgAAID3CEQAAMB7BCIAAOA9AhEAAPAegQgAAHiPQAQAALxHIAIAAN4jEAEAAO95FYhGjx5tVatWtcKFC1ujRo1s0aJFiV4kAACQBLwJRJMmTbK+ffva/fffb19++aXVr1/fWrZsaVu3bk30ogEAgATzJhCNGDHCunXrZrfffrvVrl3bxo4da0WLFrXx48cnetEAAECCeRGIUlJSbMmSJda8efPIY3nz5nX3Fy5cmNBlAwAAiZffPPDzzz/boUOHrHz58jGP6/6qVauOmH7//v3uFtq5c6f7u2vXrmxZvsP7f8uW+QK5QXYddzmN4xzI+WM9nGcQBOlO60UgyqyhQ4faAw88cMTjlStXTsjyAD4r+WSilwDAiX6s796920qWLHnUabwIRGXLlrV8+fLZli1bYh7X/QoVKhwx/YABA1wD7NDhw4ftl19+sTJlyliePHlyZJmRGLqaUPDdsGGDlShRItGLAyCbcKz7IQgCF4YqVaqU7rReBKKCBQtagwYNbM6cOdamTZtIyNH9Xr16HTF9oUKF3C1aqVKlcmx5kXg6QXKSBHI/jvXcr2Q6JUNeBSJRiU+nTp2sYcOG9oc//MGefPJJ27t3r+t1BgAA/OZNILr55ptt27ZtNmjQINu8ebOde+65Nn369CMaWgMAAP94E4hE1WOpVZEBIVWVavDO+CpTALkLxzri5Qky0hcNAAAgF/NiYEYAAICjIRABAADvEYgAAID3CETw2uWXX269e/dO9GIAABKMQAQv3HbbbW6U8fjbsGHD7MEHH0z04gHIomP80UcfjXn8nXfe4RcGkCEEInjjqquusk2bNsXcNIL5SSedlOZrUlJScnQZARy7woUL22OPPWa//vprohcFJyACEbyh8Ub023XRt2bNmsVUmVWtWtWVGHXs2NEN53/HHXe4xz/99FO79NJLrUiRIu73j+6++2430jmA5NG8eXN3XOsHutPy1ltvWZ06ddz5QMf78OHDY57XY4888oh17tzZXSydfvrpNm7cuBxYeiQagQiI88QTT1j9+vXtq6++svvuu89++OEHV7rUtm1bW7ZsmU2aNMkFJAb5BJKLfsRbYWbUqFH2448/HvH8kiVL7E9/+pO1a9fOli9fboMHD3bH+IQJE2KmU0jSzzzpHPCXv/zFevToYatXr87BT4JEYGBGeNO+4NVXX3VF6qFWrVq5n3PRz7jot+3Cq8PzzjvPpkyZEpmua9eu7kT73HPPRR5TILrssstcKVH0PAEk7hjfsWOHazPUuHFjq127tr3wwgvu/g033OB+9bx9+/bumJ85c2bkdf3797dp06bZihUrIucAlQa/8sor7r5ep1KnBx54wLp3756wz4fsRwkRvNG0aVNbunRp5Pb000+nOp2uDKN9/fXX7gqyePHikVvLli3t8OHDtnbt2hxaegAZpXZEL730kn377bcxj+v+xRdfHPOY7n///fd26NChyGP16tWL/F8NshWItm7dmgNLjkTy6rfM4LdixYpZjRo1MjRdtD179tidd97p2g3FU/sCAMmlSZMm7qJlwIABruQoswoUKBBzX6FIF0DI3QhEQDrOP/98W7lyZYbCFIDkoO73qg4/++yzI4/VqlXL5s+fHzOd7p911lmuWhx+o8oMSMe9995rCxYscI2oVdWm4vV3332XRtVAEqtbt65rMxRdNX7PPffYnDlzXE/S7777zlWrPfPMM/a3v/0tocuK5EAgAtKh9gTz5s1zJ1A1tlSj60GDBlmlSpUSvWgAjmLIkCExVV0q7Z08ebK98cYbds4557jjWNMcS7Uach96mQEAAO9RQgQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAeI9ABCCpbN682e666y6rXr26FSpUyCpXrmzXXnut+8mFjJgwYYKVKlUq25cTQO7Cj7sCSBrr1q2ziy++2AWaxx9/3P0e1YEDB2zGjBnWs2dPW7VqlZ1otPzxv54OIPlQQgQgafzlL3+xPHny2KJFi6xt27buV8jr1Kljffv2tc8++8xNM2LECBeUihUr5kqP9Jo9e/a45z7++GO7/fbbbefOnW4+ug0ePNg9t3//fvcjnqeeeqp7baNGjdz00f75z3+6eRYtWtRuuOEG917xpU3PPvusnXHGGVawYEH3S+qvvPJKzPN6T01z3XXXufd56KGHrEaNGvbEE0/ETKcfCta0a9asyZZ1CSCT9FtmAJBo27dvD/LkyRM88sgjR51u5MiRwdy5c4O1a9cGc+bMCc4+++ygR48e7rn9+/cHTz75ZFCiRIlg06ZN7rZ79273XNeuXYOLLroo+OSTT4I1a9YEjz/+eFCoUKHgu+++c89/+umnQd68ed3jq1evDkaPHh2ULl06KFmyZOS933777aBAgQLuOU0zfPjwIF++fG55QjqtlitXLhg/fnzwww8/BP/973+Dhx9+OKhdu3bM57j77ruDJk2aZOk6BHDsCEQAksLnn3/uwoRCR2a8+eabQZkyZSL3X3zxxZgQIwolCi4//fRTzOPNmjULBgwY4P5/8803B61bt455vn379jHzUqDq1q1bzDR//OMfg6uvvjpyX5+hd+/eMdPoffX++oySkpISlC1bNpgwYUKmPiuA7EOVGYCk8L9ZIn2zZ8+2Zs2auaqvk046yTp06GDbt2+33377Lc3XLF++3A4dOuSq4IoXLx65zZs3z3744Qc3zerVq+0Pf/hDzOvi73/77beujVM03dfj0Ro2bBhzv1KlSta6dWsbP368u//++++7Krw//vGPGfrMALIfjaoBJIUzzzzTtak5WsNpNbq+5pprrEePHvbwww9b6dKl7dNPP7UuXbpYSkqKa/uTGrUxypcvny1ZssT9jaZglNXUdihe165dXXgbOXKkvfjii3bzzTenubwAch4lRACSgsJNy5YtbfTo0bZ3794jnt+xY4cLNIcPH7bhw4fbhRde6Ep8Nm7cGDOdGjurNCjaeeed5x7bunWra+AcfatQoYKbRg2kFy9eHPO6+Pu1atWy+fPnxzym+7Vr107381199dUuKKnB9fTp061z584ZWCsAcgqBCEDSUBhScFFV1VtvvWXff/+9q456+umnrXHjxi7AqBv7qFGj7D//+Y/r4TV27NiYeVStWtWVCGncop9//tlVpSk4tW/f3jp27Ghvv/22rV271vVkGzp0qE2bNs29TmMfffDBB65nmd73ueeesw8//NCVWoX69evnxjlSqNE0mlbzU++19Khk6rbbbrMBAwa40jB9HgBJJBvbJwFApm3cuDHo2bNnUKVKlaBgwYLBqaeeGlx33XXBRx995J4fMWJEULFixaBIkSJBy5Ytg5dfftk1ZP71118j8+jevbtraK3H77///khD5kGDBgVVq1Z1PcU0jxtuuCFYtmxZ5HXjxo1z76d5t2nTJnjooYeCChUqxCzfmDFjgurVq7t5nHXWWe79o+k9p0yZkupnU68zPT9s2LAsXWcAjl8e/ZPoUAYAyahbt26uTdO///3vLJmf5qMG4Rs2bLDy5ctnyTwBZA0aVQPA/9HgiVdeeaVr66PqspdeesnGjBlz3PNVj7Jt27a5QSLVs4wwBCQf2hABwP9RuyIFIo2ErbZJaruk3mHH6/XXX7cqVaq4huHDhg3LkmUFkLWoMgMAAN6jhAgAAHiPQAQAALxHIAIAAN4jEAEAAO8RiAAAgPcIRAAAwHsEIgAA4D0CEQAA8B6BCAAAmO/+H9W/1MF1LKCVAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Samples for the Testing Data Fire Category:\n",
      "1000\n",
      "The Number of Samples for the Testing Data Non Category:\n",
      "1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A. For the Creation of the Training Dataset and Testing Dataset Directory\n",
    "\n",
    "import os \n",
    "print(os.listdir(\"dataset\"))\n",
    "\n",
    "from pathlib import Path\n",
    "data_directory = Path(\"dataset/\")\n",
    "train_directory = data_directory/\"train\"\n",
    "test_directory = data_directory/\"test\"\n",
    "\n",
    "# B. For the Training Dataset data Distribution\n",
    "\n",
    "def load_train():\n",
    "    Fire_directory = train_directory/\"Fire\"\n",
    "    Non_directory = train_directory/\"Non\"\n",
    "    \n",
    "    # Get the List of all the Images\n",
    "    Fire = Fire_directory.glob(\"*.jpg\")\n",
    "    Non = Non_directory.glob(\"*.jpg\")\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    \n",
    "    for img in Fire: \n",
    "        train_data.append(img)\n",
    "        train_label.append(\"Fire\")\n",
    "\n",
    "    for img in Non: \n",
    "        train_data.append(img)\n",
    "        train_label.append(\"Non\")\n",
    "        \n",
    "    dataframe = pd.DataFrame(train_data)\n",
    "    dataframe.columns = [\"images\"]\n",
    "    dataframe[\"labels\"] = train_label\n",
    "    dataframe = dataframe.sample(frac = 1).reset_index(drop = True)\n",
    "    return dataframe\n",
    "\n",
    "train_data = load_train()\n",
    "train_data.shape \n",
    "\n",
    "index_training_data = train_data[\"labels\"].value_counts().index\n",
    "values_training_data = train_data[\"labels\"].value_counts().values\n",
    "train_data_distribution = [index_training_data , values_training_data]\n",
    "print(\"The Number of Samples for the Training Data Fire Category:\")\n",
    "print(values_training_data[0])\n",
    "print(\"The Number of Samples for the Training Data Non-Fire Category:\")\n",
    "print(values_training_data[1])\n",
    "\n",
    "plt.bar(index_training_data , values_training_data)\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of the Training Data based from Category\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# C. For the Testing Dataset data Distribution\n",
    "\n",
    "def load_test():\n",
    "    Fire_directory = test_directory/\"Fire\"\n",
    "    Non_directory = test_directory/\"Non\"\n",
    "    \n",
    "    # Get the List of all the Images\n",
    "    Fire = Fire_directory.glob(\"*.jpg\")\n",
    "    Non = Non_directory.glob(\"*.jpg\")\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "    \n",
    "    for img in Fire: \n",
    "        test_data.append(img)\n",
    "        test_label.append(\"Fire\")\n",
    "\n",
    "    for img in Non: \n",
    "        test_data.append(img)\n",
    "        test_label.append(\"Non\")\n",
    "        \n",
    "    dataframe = pd.DataFrame(test_data)\n",
    "    dataframe.columns = [\"images\"]\n",
    "    dataframe[\"labels\"] = test_label\n",
    "    dataframe = dataframe.sample(frac = 1).reset_index(drop = True)\n",
    "    return dataframe\n",
    "\n",
    "test_data = load_test()\n",
    "test_data.shape \n",
    "\n",
    "index_testing_data = test_data[\"labels\"].value_counts().index\n",
    "values_testing_data = test_data[\"labels\"].value_counts().values\n",
    "test_data_distribution = [index_testing_data , values_testing_data]\n",
    "print(\"The Number of Samples for the Testing Data Fire Category:\")\n",
    "print(values_testing_data[0])\n",
    "print(\"The Number of Samples for the Testing Data Non Category:\")\n",
    "print(values_testing_data[1])\n",
    "\n",
    "plt.bar(index_testing_data , values_testing_data)\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Distribution of the Testing Data based from Category\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e4109",
   "metadata": {},
   "source": [
    "# PART 3: Citting the CNN Model to the Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabb1bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6003 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/50\n",
      "\u001b[1m188/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m19s\u001b[0m 321ms/step - accuracy: 0.5486 - loss: 0.6874 - mse: 0.2471"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bened\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "C:\\Users\\bened\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 323ms/step - accuracy: 0.5537 - loss: 0.6859 - mse: 0.2464 - val_accuracy: 0.4103 - val_loss: 0.7258 - val_mse: 0.2662\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 66ms/step - accuracy: 0.6111 - loss: 0.6600 - mse: 0.2339 - val_accuracy: 0.4244 - val_loss: 0.8004 - val_mse: 0.3003\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.6225 - loss: 0.6446 - mse: 0.2268 - val_accuracy: 0.4491 - val_loss: 0.7984 - val_mse: 0.2988\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 67ms/step - accuracy: 0.6160 - loss: 0.6417 - mse: 0.2256 - val_accuracy: 0.4425 - val_loss: 0.8027 - val_mse: 0.2999\n",
      "Epoch 5/50\n",
      "\u001b[1m 96/250\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 69ms/step - accuracy: 0.6451 - loss: 0.6270 - mse: 0.2186"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 89\u001b[0m\n\u001b[0;32m     47\u001b[0m test_datagenerator \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     48\u001b[0m     featurewise_center\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m     samplewise_center\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m     interpolation_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     70\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     72\u001b[0m testing_set \u001b[38;5;241m=\u001b[39m test_datagenerator\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/test\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     74\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     86\u001b[0m     interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     87\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 89\u001b[0m records \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m                         \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# training data/batch size = 8048/32 =251.5\u001b[39;49;00m\n\u001b[0;32m     91\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtesting_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m62\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# testing data/batch size = 2000/32 = 62.5\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# 8048 / 32 = 252 approx\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# divide the whole testing dataset sa no. of epoch\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# 2000 / 32 = 63 \u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[0;32m    100\u001b[0m \n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# To Save the Trained Model\u001b[39;00m\n\u001b[0;32m    103\u001b[0m classifier\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    219\u001b[0m     ):\n\u001b[1;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Saved on the Disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagenerator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.0,\n",
    "    horizontal_flip= True,\n",
    "    vertical_flip= True,\n",
    "    rescale= 1./255,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    interpolation_order=1,\n",
    "    dtype=None)\n",
    "\n",
    "\n",
    "training_set = train_datagenerator.flow_from_directory(\n",
    "    \"dataset/train\",\n",
    "    target_size=(64, 64),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    save_to_dir=None,\n",
    "    save_prefix='',\n",
    "    save_format='jpg',\n",
    "    follow_links=False,\n",
    "    subset=None,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False)\n",
    "\n",
    "\n",
    "test_datagenerator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.0,\n",
    "    horizontal_flip= True,\n",
    "    vertical_flip= True,\n",
    "    rescale= 1./255,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    interpolation_order=1,\n",
    "    dtype=None)\n",
    "\n",
    "testing_set = test_datagenerator.flow_from_directory(\n",
    "    \"dataset/test\",\n",
    "    target_size=(64, 64),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    save_to_dir=None,\n",
    "    save_prefix='',\n",
    "    save_format='jpg',\n",
    "    follow_links=False,\n",
    "    subset=None,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False)\n",
    "\n",
    "records = classifier.fit(training_set,\n",
    "                         steps_per_epoch = 250, # training data/batch size = 8048/32 =251.5\n",
    "                         epochs = 50, \n",
    "                         validation_data = testing_set, \n",
    "                         validation_steps = 62) # testing data/batch size = 2000/32 = 62.5\n",
    "\n",
    "\n",
    "# 8048 / 32 = 252 approx\n",
    "# divide the whole testing dataset sa no. of epoch\n",
    "# 2000 / 32 = 63 \n",
    "\n",
    "\n",
    "# To Save the Trained Model\n",
    "\n",
    "classifier.save(\"cnn.h5\")\n",
    "print(\"Classifier Saved on the Disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d423735",
   "metadata": {},
   "source": [
    "# PART 4: Plotting the Loss, Accuracy and MSE Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af44edad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.Plotting the loss Chart\n",
    "\n",
    "classifier_dictionary = records.history\n",
    " \n",
    "training_loss_values = classifier_dictionary[\"loss\"]\n",
    "validation_loss_values = classifier_dictionary[\"val_loss\"]\n",
    "epochs = range(1, len(training_loss_values) + 1)\n",
    " \n",
    "line1 = plt.plot(epochs, validation_loss_values, label = \"Validation or Testing Loss\")\n",
    "line2 = plt.plot(epochs, training_loss_values, label = \"Training Loss\")\n",
    "plt.setp(line1, linewidth = 2.0, marker = \"+\", markersize = 10.0)\n",
    "plt.setp(line2, linewidth = 2.0, marker = \"4\", markersize = 10.0)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# B. Plotting the Accuracy Charts\n",
    " \n",
    "classifier_dictionary = records.history\n",
    " \n",
    "training_accuracy_values = classifier_dictionary[\"accuracy\"]\n",
    "validation_accuracy_values = classifier_dictionary[\"val_accuracy\"]\n",
    "epochs = range(1, len(training_accuracy_values) + 1)\n",
    " \n",
    "line1 = plt.plot(epochs, validation_accuracy_values, label = \"Validation or Testing Accuracy\")\n",
    "line2 = plt.plot(epochs, training_accuracy_values, label = \"Training Accuracy\")\n",
    "plt.setp(line1, linewidth = 2.0, marker = \"+\", markersize = 10.0)\n",
    "plt.setp(line2, linewidth = 2.0, marker = \"4\", markersize = 10.0)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    " # C. Plotting the MSE Charts\n",
    " \n",
    "classifier_dictionary = records.history\n",
    " \n",
    "training_mse_values = classifier_dictionary[\"mse\"]\n",
    "validation_mse_values = classifier_dictionary[\"val_mse\"]\n",
    "epochs = range(1, len(training_mse_values) + 1)\n",
    " \n",
    "line1 = plt.plot(epochs, validation_mse_values, label = \"Validation or Testing MSE\")\n",
    "line2 = plt.plot(epochs, training_mse_values, label = \"Training MSE\")\n",
    "plt.setp(line1, linewidth = 2.0, marker = \"+\", markersize = 10.0)\n",
    "plt.setp(line2, linewidth = 2.0, marker = \"4\", markersize = 10.0)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3cf847",
   "metadata": {},
   "source": [
    "# PART 5: Evaluating the Performance of the Model Using the Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b0288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model on the Testing Dataset\n",
    "evaluation_results = classifier.evaluate(testing_set, batch_size = 32, verbose = 1)\n",
    "\n",
    "# To Print the Evaluation metrics \n",
    "for metric_name, metric_value in zip(classifier.metrics_names, evaluation_results):\n",
    "    print(\"\")\n",
    "    print(f\"{metric_name}: {metric_value}\")\n",
    "    \n",
    "# To Get the Classifier Prediction using the Testing Dataset\n",
    "prediction_probability = classifier.predict(testing_set)\n",
    "prediction = np.rint(prediction_probability)\n",
    "\n",
    "# To Generate the Testing Dataset Labels\n",
    "testing_dataset_labels = test_data[\"labels\"]\n",
    "testing_dataset_labels = np.where(testing_dataset_labels == \"Fire\", 0, 1)\n",
    "#testing_dataset_labels = testing_dataset_labels.values\n",
    "\n",
    "#testing_dataset_labels = testing_set.classes\n",
    "\n",
    "# To Generate the Plot of the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(testing_dataset_labels, prediction)\n",
    "\n",
    "# Conda install seaborn\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.ylabel('Actual Value')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424cbb56",
   "metadata": {},
   "source": [
    "# PART 6: PERFORM HOLD-OUT VALIDATION TO ASSESS THE ARTIFICIAL NEURAL NETWORK MODEL'S PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion_matrix[1, 1]\n",
    "TN = confusion_matrix[0, 0]\n",
    "FP = confusion_matrix[0, 1]\n",
    "FN = confusion_matrix[1, 0]\n",
    "\n",
    "# A. For the Classification Accuracy\n",
    "# Overall, how often is the classifier correct?\n",
    "# It is the proportion of correct predictions over the total number of predictions.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(testing_dataset_labels, prediction)\n",
    "print(\"Classification Accuracy: %.4f\"\n",
    "      %classification_accuracy)\n",
    "print(' ')\n",
    "\n",
    "# classification_accuracy = (TP+TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# B. For the Classification Error\n",
    "# Overall, how often is the classifier incorrect?\n",
    "# All false predictions over the total number of predictions.\n",
    "\n",
    "classification_error = 1 - classification_accuracy\n",
    "print(\"Classification Error: %.4f\"\n",
    "      %classification_error)\n",
    "print(' ')\n",
    "\n",
    "# classification_error = (FP + FN) / (TP + TN + FP + FN)\n",
    "\n",
    "# C. For the Sensitivity, Recall Score, Probability of Detection, or True Positive Rate\n",
    "# When the actual value is positive, how often is the prediction correct?\n",
    "# Out of all actual Positives, how many did we predict as Positive?\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "sensitivity = recall_score(testing_dataset_labels, prediction)\n",
    "print('Sensitivity: %.4f' \n",
    "      % sensitivity)\n",
    "print(' ')\n",
    "\n",
    "# sensitivity = TP / (TP + FN)\n",
    "\n",
    "# D. For the Specificity or True Negative Rate\n",
    "# When the actual value is negative, how often is the prediction correct?\n",
    "# Out of all actual Negatives, how many did we predict as Negative?\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "print('Specificity: %.4f' \n",
    "      % specificity)\n",
    "print(' ')\n",
    "\n",
    "# E. For the False Positive Rate\n",
    "# When the actual value is negative, how often is the prediction incorrect?\n",
    "\n",
    "false_positive_rate = 1 - specificity\n",
    "print('False Positive Rate: %.4f' \n",
    "      % false_positive_rate)\n",
    "print(' ')\n",
    "\n",
    "# false_positive_rate = FN / (TN + FP)\n",
    "\n",
    "# F. For the Precision or Positive Predictive Value \n",
    "# When a positive value is predicted, how often is the prediction correct?\n",
    "# Out of all predicted Positive cases, how many were actually Positive?\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(testing_dataset_labels, prediction)\n",
    "print('Precision: %.4f' \n",
    "      % precision)\n",
    "print(' ')\n",
    "\n",
    "# precision = TP / (TP + FP)\n",
    "\n",
    "# G. For the F1-Score\n",
    " # It is the harmonic, or weighted, an average of Precision and Sensitivity.\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(testing_dataset_labels, prediction)\n",
    "print('F1-Score: %.4f' \n",
    "      % f1_score)\n",
    "print(' ')\n",
    "\n",
    "# f1_score = 2*precision*sensitivity / (precision + sensitivity)\n",
    "\n",
    "# H. For the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "classification_report = classification_report(testing_dataset_labels, prediction)\n",
    "\n",
    "# I. For the Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision_value, recall_value, threshold = precision_recall_curve(testing_dataset_labels, prediction)\n",
    "\n",
    "plt.plot(precision_value, recall_value)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.title(\"Precision-Recall Curve for the Artificial Neural Network Model\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "\n",
    "# J. For The ROC Curve with AUC\n",
    "# A Receiver Operating Characteristic Curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. \n",
    "# The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n",
    "\n",
    "# J.1. For the Receiver Operating Curve (ROC)\n",
    "from sklearn.metrics import roc_curve\n",
    "FPR, TPR, threshold = roc_curve(testing_dataset_labels, prediction)\n",
    "\n",
    "# J.2. For the Area Under the Curve (AUC)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "AUC_score = roc_auc_score(testing_dataset_labels, prediction)\n",
    "\n",
    "# The perfect model will have an AUC of 1.0. The closer the AUC to 1.0, the better the predictions.\n",
    "   \n",
    "# J.3. To Plot the ROC Curve with AUC\n",
    "plt.plot(FPR, TPR, label = \"ROC Curve\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# J.4. For the Plot of Baseline for AUC\n",
    "# The 45-degree line is the baseline for which the AUC is 0.5. \n",
    "\n",
    "plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10), label='Baseline', linestyle='--')\n",
    "plt.title(f'ROC Curve with AUC = {round(AUC_score,4)} for the Artificial Neural Network Model')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.legend();\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc63446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import load_img\n",
    "from keras.utils import img_to_array\n",
    "\n",
    "# A. To Load the Trained Model\n",
    "\n",
    "from keras.models import load_model\n",
    "classifier = load_model(\"cnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c4f1b",
   "metadata": {},
   "source": [
    "# Part 7: Making SIngle Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. For the First Single Image\n",
    "\n",
    "test_image = load_img(\"dataset/single_prediction/fire_test.jpg\", target_size = (64, 64))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "prediction = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if prediction[0][0] == 1:\n",
    "    prediction = 'Fire'      \n",
    "else: \n",
    "    prediction = 'Non-Fire'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c96cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. For the Second Single Image\n",
    "\n",
    "test_image = load_img(\"dataset/single_prediction/non_test.jpg\", target_size = (64, 64))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "prediction = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if prediction[0][0] == 1:\n",
    "    prediction = 'Fire'   \n",
    "else: \n",
    "    prediction = 'Non-Fire'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526c795",
   "metadata": {},
   "source": [
    "# Part 8 Opmtimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7592fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from keras_tuner import Hyperband\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Ftrl\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the model for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=32), \n",
    "                     kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]), \n",
    "                     activation='relu', input_shape=(128, 128, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=hp.Int('conv_2_filter', min_value=32, max_value=128, step=32), \n",
    "                     kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=hp.Int('conv_3_filter', min_value=64, max_value=256, step=64), \n",
    "                     kernel_size=hp.Choice('conv_3_kernel', values=[3, 5]), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(filters=hp.Int('conv_4_filter', min_value=64, max_value=256, step=64), \n",
    "                     kernel_size=hp.Choice('conv_4_kernel', values=[3, 5]), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=hp.Int('dense_1_units', min_value=128, max_value=512, step=64), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('dense_2_units', min_value=64, max_value=256, step=64), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop']),\n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy','mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b8361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the HyperParameters\n",
    "from keras_tuner import HyperParameters\n",
    "\n",
    "hp = HyperParameters()\n",
    "hp.Choice('learning_rate', values=[0.001, 0.01, 0.1])\n",
    "hp.Choice('batch_size', values=[16, 32, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='dataset',\n",
    "    project_name='Deep_Problem_3'\n",
    ")\n",
    "\n",
    "learning_rate = hp.get('learning_rate')\n",
    "batch_size = hp.get('batch_size')\n",
    "\n",
    "print(\"Learning Rate:\", learning_rate)\n",
    "print(\"Batch Size:\", batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fbb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    interpolation_order=1,\n",
    "    dtype=None\n",
    ")\n",
    "\n",
    "training_set = train_data_generator.flow_from_directory(\n",
    "    \"dataset/train\",\n",
    "    target_size=(128, 128),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    save_to_dir=None,\n",
    "    save_prefix='',\n",
    "    save_format='jpg',\n",
    "    follow_links=False,\n",
    "    subset=None,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")\n",
    "\n",
    "testing_datagenerator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=None,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.0,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.0,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=None,\n",
    "    data_format=None,\n",
    "    validation_split=0.0,\n",
    "    interpolation_order=1,\n",
    "    dtype=None\n",
    "    \n",
    ")\n",
    "\n",
    "testing_set = testing_datagenerator.flow_from_directory(\n",
    "    \"dataset/test\",\n",
    "    target_size=(128, 128),\n",
    "    color_mode='rgb',\n",
    "    classes=None,\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    subset=None,\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    save_to_dir=None,\n",
    "    save_prefix='',\n",
    "    save_format='jpg',\n",
    "    follow_links=False,\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcadaf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs= 10,\n",
    "    hyperparameters=hp,\n",
    "    executions_per_trial=1,\n",
    "    directory='DL_Project',\n",
    "    project_name='hyperband_optimizing',\n",
    ")\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class EarlyStopByAccuracy(Callback):\n",
    "    def __init__(self, threshold=0.6):\n",
    "        super(EarlyStopByAccuracy, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        if epoch == 0:  # Check the accuracy after the first epoch\n",
    "            accuracy = logs.get('accuracy')\n",
    "            if accuracy is not None and accuracy < self.threshold:\n",
    "                self.model.stop_training = True\n",
    "                print(f\"\\nEpoch {epoch+1}: early stopping as accuracy {accuracy:.4f} is below threshold {self.threshold:.4f}\")\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopByAccuracy(threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d97b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform the hyperparameter search\n",
    "tuner.search(training_set,\n",
    "             epochs=10,  # Increase the number of epochs\n",
    "             validation_data=testing_set,\n",
    "            callbacks=[early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e91ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal learning rate for the optimizer is {best_hps.get('learning_rate')} \n",
    "and the optimal number of units in the first densely-connected layer is {best_hps.get('dense_1_units')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters\n",
    "print(\"The best hyperparameters are:\")\n",
    "for param, value in best_hps.values.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc375ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbbacks\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad02163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 342ms/step - accuracy: 0.9335 - loss: 0.1598 - mse: 0.0474 - val_accuracy: 0.8660 - val_loss: 0.3219 - val_mse: 0.0979\n",
      "Epoch 43/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 340ms/step - accuracy: 0.9378 - loss: 0.1530 - mse: 0.0450 - val_accuracy: 0.8090 - val_loss: 0.5172 - val_mse: 0.1475\n",
      "Epoch 44/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 342ms/step - accuracy: 0.9330 - loss: 0.1768 - mse: 0.0523 - val_accuracy: 0.8210 - val_loss: 0.5207 - val_mse: 0.1426\n",
      "Epoch 45/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 366ms/step - accuracy: 0.9390 - loss: 0.1569 - mse: 0.0451 - val_accuracy: 0.8735 - val_loss: 0.3264 - val_mse: 0.0949\n",
      "Epoch 46/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 340ms/step - accuracy: 0.9408 - loss: 0.1606 - mse: 0.0464 - val_accuracy: 0.8665 - val_loss: 0.3388 - val_mse: 0.1000\n",
      "Epoch 47/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9374 - loss: 0.1573 - mse: 0.0464 - val_accuracy: 0.8380 - val_loss: 0.4007 - val_mse: 0.1191\n",
      "Epoch 48/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9350 - loss: 0.1627 - mse: 0.0468 - val_accuracy: 0.8380 - val_loss: 0.3949 - val_mse: 0.1197\n",
      "Epoch 49/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 334ms/step - accuracy: 0.9441 - loss: 0.1459 - mse: 0.0423 - val_accuracy: 0.8360 - val_loss: 0.3716 - val_mse: 0.1181\n",
      "Epoch 50/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 334ms/step - accuracy: 0.9427 - loss: 0.1484 - mse: 0.0430 - val_accuracy: 0.8785 - val_loss: 0.2853 - val_mse: 0.0873\n",
      "Epoch 51/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 334ms/step - accuracy: 0.9413 - loss: 0.1573 - mse: 0.0445 - val_accuracy: 0.8550 - val_loss: 0.3760 - val_mse: 0.1091\n",
      "Epoch 52/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 334ms/step - accuracy: 0.9431 - loss: 0.1530 - mse: 0.0428 - val_accuracy: 0.8565 - val_loss: 0.3550 - val_mse: 0.1088\n",
      "Epoch 53/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9328 - loss: 0.1685 - mse: 0.0496 - val_accuracy: 0.8725 - val_loss: 0.3244 - val_mse: 0.0955\n",
      "Epoch 54/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9363 - loss: 0.1675 - mse: 0.0485 - val_accuracy: 0.8270 - val_loss: 0.4147 - val_mse: 0.1259\n",
      "Epoch 55/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9392 - loss: 0.1563 - mse: 0.0447 - val_accuracy: 0.8830 - val_loss: 0.2816 - val_mse: 0.0859\n",
      "Epoch 56/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9474 - loss: 0.1481 - mse: 0.0422 - val_accuracy: 0.8715 - val_loss: 0.3123 - val_mse: 0.0951\n",
      "Epoch 57/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9395 - loss: 0.1613 - mse: 0.0459 - val_accuracy: 0.8925 - val_loss: 0.2799 - val_mse: 0.0830\n",
      "Epoch 58/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9371 - loss: 0.1595 - mse: 0.0464 - val_accuracy: 0.8445 - val_loss: 0.4799 - val_mse: 0.1231\n",
      "Epoch 59/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9470 - loss: 0.1402 - mse: 0.0405 - val_accuracy: 0.8835 - val_loss: 0.2949 - val_mse: 0.0890\n",
      "Epoch 60/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 334ms/step - accuracy: 0.9310 - loss: 0.1678 - mse: 0.0504 - val_accuracy: 0.8765 - val_loss: 0.3151 - val_mse: 0.0911\n",
      "Epoch 61/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9431 - loss: 0.1526 - mse: 0.0451 - val_accuracy: 0.8915 - val_loss: 0.2822 - val_mse: 0.0832\n",
      "Epoch 62/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 334ms/step - accuracy: 0.9435 - loss: 0.1452 - mse: 0.0415 - val_accuracy: 0.8470 - val_loss: 0.4128 - val_mse: 0.1197\n",
      "Epoch 63/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9375 - loss: 0.1553 - mse: 0.0456 - val_accuracy: 0.8725 - val_loss: 0.3379 - val_mse: 0.0996\n",
      "Epoch 64/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9462 - loss: 0.1481 - mse: 0.0422 - val_accuracy: 0.8720 - val_loss: 0.3341 - val_mse: 0.1004\n",
      "Epoch 65/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9407 - loss: 0.1468 - mse: 0.0427 - val_accuracy: 0.8715 - val_loss: 0.3126 - val_mse: 0.0945\n",
      "Epoch 66/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9492 - loss: 0.1401 - mse: 0.0402 - val_accuracy: 0.8485 - val_loss: 0.3810 - val_mse: 0.1135\n",
      "Epoch 67/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9455 - loss: 0.1456 - mse: 0.0420 - val_accuracy: 0.8205 - val_loss: 0.5999 - val_mse: 0.1450\n",
      "Epoch 68/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9393 - loss: 0.1522 - mse: 0.0451 - val_accuracy: 0.8580 - val_loss: 0.3649 - val_mse: 0.1053\n",
      "Epoch 69/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 338ms/step - accuracy: 0.9448 - loss: 0.1461 - mse: 0.0428 - val_accuracy: 0.8685 - val_loss: 0.3284 - val_mse: 0.0956\n",
      "Epoch 70/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 337ms/step - accuracy: 0.9462 - loss: 0.1406 - mse: 0.0411 - val_accuracy: 0.8480 - val_loss: 0.4390 - val_mse: 0.1198\n",
      "Epoch 71/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 338ms/step - accuracy: 0.9496 - loss: 0.1289 - mse: 0.0377 - val_accuracy: 0.8220 - val_loss: 0.4592 - val_mse: 0.1329\n",
      "Epoch 72/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9490 - loss: 0.1350 - mse: 0.0389 - val_accuracy: 0.8805 - val_loss: 0.2830 - val_mse: 0.0858\n",
      "Epoch 73/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9466 - loss: 0.1414 - mse: 0.0407 - val_accuracy: 0.8700 - val_loss: 0.3167 - val_mse: 0.0953\n",
      "Epoch 74/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9481 - loss: 0.1376 - mse: 0.0403 - val_accuracy: 0.8770 - val_loss: 0.2952 - val_mse: 0.0909\n",
      "Epoch 75/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9405 - loss: 0.1387 - mse: 0.0415 - val_accuracy: 0.8740 - val_loss: 0.3062 - val_mse: 0.0935\n",
      "Epoch 76/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 337ms/step - accuracy: 0.9519 - loss: 0.1360 - mse: 0.0388 - val_accuracy: 0.8505 - val_loss: 0.4050 - val_mse: 0.1154\n",
      "Epoch 77/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9515 - loss: 0.1289 - mse: 0.0367 - val_accuracy: 0.8735 - val_loss: 0.3212 - val_mse: 0.0958\n",
      "Epoch 78/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9431 - loss: 0.1412 - mse: 0.0415 - val_accuracy: 0.8670 - val_loss: 0.3473 - val_mse: 0.1001\n",
      "Epoch 79/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 337ms/step - accuracy: 0.9485 - loss: 0.1318 - mse: 0.0388 - val_accuracy: 0.8415 - val_loss: 0.3812 - val_mse: 0.1155\n",
      "Epoch 80/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 338ms/step - accuracy: 0.9495 - loss: 0.1308 - mse: 0.0383 - val_accuracy: 0.8785 - val_loss: 0.3027 - val_mse: 0.0899\n",
      "Epoch 81/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9469 - loss: 0.1391 - mse: 0.0404 - val_accuracy: 0.8750 - val_loss: 0.3236 - val_mse: 0.0940\n",
      "Epoch 82/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9441 - loss: 0.1354 - mse: 0.0402 - val_accuracy: 0.8620 - val_loss: 0.3310 - val_mse: 0.0984\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9553 - loss: 0.1166 - mse: 0.0337 - val_accuracy: 0.8765 - val_loss: 0.3528 - val_mse: 0.0972\n",
      "Epoch 84/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9377 - loss: 0.1560 - mse: 0.0459 - val_accuracy: 0.8930 - val_loss: 0.2760 - val_mse: 0.0797\n",
      "Epoch 85/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 335ms/step - accuracy: 0.9519 - loss: 0.1207 - mse: 0.0352 - val_accuracy: 0.8515 - val_loss: 0.3730 - val_mse: 0.1086\n",
      "Epoch 86/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9400 - loss: 0.1478 - mse: 0.0430 - val_accuracy: 0.8875 - val_loss: 0.2875 - val_mse: 0.0841\n",
      "Epoch 87/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 334ms/step - accuracy: 0.9454 - loss: 0.1320 - mse: 0.0393 - val_accuracy: 0.8895 - val_loss: 0.2660 - val_mse: 0.0806\n",
      "Epoch 88/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9443 - loss: 0.1389 - mse: 0.0405 - val_accuracy: 0.9060 - val_loss: 0.2468 - val_mse: 0.0708\n",
      "Epoch 89/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 334ms/step - accuracy: 0.9474 - loss: 0.1291 - mse: 0.0381 - val_accuracy: 0.8720 - val_loss: 0.3089 - val_mse: 0.0929\n",
      "Epoch 90/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 340ms/step - accuracy: 0.9587 - loss: 0.1138 - mse: 0.0321 - val_accuracy: 0.8775 - val_loss: 0.3378 - val_mse: 0.0938\n",
      "Epoch 91/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9497 - loss: 0.1387 - mse: 0.0388 - val_accuracy: 0.8700 - val_loss: 0.3517 - val_mse: 0.1023\n",
      "Epoch 92/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 338ms/step - accuracy: 0.9571 - loss: 0.1208 - mse: 0.0348 - val_accuracy: 0.8950 - val_loss: 0.2782 - val_mse: 0.0817\n",
      "Epoch 93/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9532 - loss: 0.1218 - mse: 0.0355 - val_accuracy: 0.8505 - val_loss: 0.3875 - val_mse: 0.1120\n",
      "Epoch 94/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 340ms/step - accuracy: 0.9532 - loss: 0.1128 - mse: 0.0329 - val_accuracy: 0.8535 - val_loss: 0.3992 - val_mse: 0.1113\n",
      "Epoch 95/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 339ms/step - accuracy: 0.9457 - loss: 0.1403 - mse: 0.0405 - val_accuracy: 0.8305 - val_loss: 0.4831 - val_mse: 0.1323\n",
      "Epoch 96/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 339ms/step - accuracy: 0.9582 - loss: 0.1113 - mse: 0.0317 - val_accuracy: 0.8665 - val_loss: 0.3602 - val_mse: 0.1021\n",
      "Epoch 97/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 340ms/step - accuracy: 0.9506 - loss: 0.1237 - mse: 0.0363 - val_accuracy: 0.9015 - val_loss: 0.2444 - val_mse: 0.0713\n",
      "Epoch 98/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 338ms/step - accuracy: 0.9545 - loss: 0.1233 - mse: 0.0354 - val_accuracy: 0.8860 - val_loss: 0.2895 - val_mse: 0.0837\n",
      "Epoch 99/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 336ms/step - accuracy: 0.9553 - loss: 0.1156 - mse: 0.0327 - val_accuracy: 0.8980 - val_loss: 0.2956 - val_mse: 0.0794\n",
      "Epoch 100/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 339ms/step - accuracy: 0.9542 - loss: 0.1223 - mse: 0.0349 - val_accuracy: 0.8850 - val_loss: 0.3005 - val_mse: 0.0862\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(\n",
    "    training_set,\n",
    "    epochs= 100,  # Train for more epochs to ensure the model learns well\n",
    "    validation_data=testing_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff0c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Plotting the Loss Charts\n",
    "\n",
    "classifier_dictionary = history.history\n",
    "training_loss_values = classifier_dictionary['loss']\n",
    "validation_loss_values = classifier_dictionary['val_loss']\n",
    "epochs = range(1, len(training_loss_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, validation_loss_values, label = 'Validation or Testing loss')\n",
    "line2 = plt.plot(epochs, training_loss_values, label = 'Training loss')\n",
    "plt.setp(line1, linewidth = 2.0, marker = '+', markersize = 10.0)\n",
    "plt.setp(line2, linewidth = 2.0, marker = '4', markersize = 10.0)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76be5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dictionary = history.history\n",
    "\n",
    "training_accuracy_values = classifier_dictionary['accuracy']\n",
    "validation_accuracy_values = classifier_dictionary['val_accuracy']\n",
    "epochs = range(1, len(training_accuracy_values) + 1)\n",
    "\n",
    "plt.plot(epochs, training_accuracy_values, label=\"Training Accuracy\")\n",
    "plt.plot(epochs, validation_accuracy_values, label=\"Validation Accuracy\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea82ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Plotting the MSE Charts\n",
    "\n",
    "classifier_dictionary = history.history\n",
    "\n",
    "training_mse_values = classifier_dictionary['mse']\n",
    "validation_mse_values = classifier_dictionary['val_mse']\n",
    "epochs = range(1, len(training_mse_values) + 1)\n",
    "\n",
    "line1 = plt.plot(epochs, validation_mse_values, label = 'Validation or Testing MSE')\n",
    "line2 = plt.plot(epochs, training_mse_values, label = 'Training MSE')\n",
    "plt.setp(line1, linewidth = 2.0, marker = '+', markersize = 10.0)\n",
    "plt.setp(line2, linewidth = 2.0, marker = '4', markersize = 10.0)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MSE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafd832",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results = best_model.evaluate(testing_set, batch_size=32, verbose=1)\n",
    "for metric_name, metric_value in zip(best_model.metrics_names, evaluation_results):\n",
    "    print(f'{metric_name}: {metric_value}')\n",
    "\n",
    "prediction_proba = best_model.predict(testing_set)\n",
    "prediction = np.rint(prediction_proba)\n",
    "\n",
    "testing_dataset_labels = testing_set.classes\n",
    " \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(testing_dataset_labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ca950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in TensorFlow SavedModel format\n",
    "best_model.save(\"CNN_BEST_MODEL.h5\")\n",
    "\n",
    "print(\"Classifier Saved in the Disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.xlabel(\"Predicted Value\")\n",
    "plt.ylabel(\"Actual Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Computing the Hold-out Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(testing_dataset_labels, prediction)\n",
    "print(\"Hold-out Accuracy:\")\n",
    "print(accuracy)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729cef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. Generating the Classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(testing_dataset_labels, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e183e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = confusion_matrix[1, 1]\n",
    "TN = confusion_matrix[0, 0]\n",
    "FP = confusion_matrix[0, 1]\n",
    "FN = confusion_matrix[1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc38b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. For the Classification Accuracy\n",
    "# Overall, how often is the classifier correct?\n",
    "# It is the proportion of correct predictions over the total number of predictions.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "classification_accuracy = accuracy_score(testing_dataset_labels, prediction)\n",
    "print(\"Classification Accuracy: %.4f\"\n",
    "      %classification_accuracy)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. For the Sensitivity, Recall Score, Probability of Detection, or True Positive Rate\n",
    "# When the actual value is positive, how often is the prediction correct?\n",
    "# Out of all actual Positives, how many did we predict as Positive?\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "sensitivity = recall_score(testing_dataset_labels, prediction)\n",
    "print('Sensitivity: %.4f' \n",
    "      % sensitivity)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e91990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D. For the Specificity or True Negative Rate\n",
    "# When the actual value is negative, how often is the prediction correct?\n",
    "# Out of all actual Negatives, how many did we predict as Negative?\n",
    "\n",
    "specificity = TN / (TN + FP)\n",
    "print('Specificity: %.4f' \n",
    "      % specificity)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# E. For the False Positive Rate\n",
    "# When the actual value is negative, how often is the prediction incorrect?\n",
    "\n",
    "false_positive_rate = 1 - specificity\n",
    "print('False Positive Rate: %.4f' \n",
    "      % false_positive_rate)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d5543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F. For the Precision or Positive Predictive Value \n",
    "# When a positive value is predicted, how often is the prediction correct?\n",
    "# Out of all predicted Positive cases, how many were actually Positive?\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(testing_dataset_labels, prediction)\n",
    "print('Precision: %.4f' \n",
    "      % precision)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be25b4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G. For the F1-Score\n",
    " # It is the harmonic, or weighted, an average of Precision and Sensitivity.\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score = f1_score(testing_dataset_labels, prediction)\n",
    "print('F1-Score: %.4f' \n",
    "      % f1_score)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2168694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H. For the Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "classification_report = classification_report(testing_dataset_labels, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I. For the Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precision_value, recall_value, threshold = precision_recall_curve(testing_dataset_labels, prediction)\n",
    "\n",
    "plt.plot(precision_value, recall_value)\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.title(\"Precision-Recall Curve for the Artificial Neural Network Model\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1a4ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# J. For The ROC Curve with AUC\n",
    "# J.1. For the Receiver Operating Curve (ROC)\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "FPR, TPR, threshold = roc_curve(testing_dataset_labels, prediction)\n",
    "\n",
    "# J.2. For the Area Under the Curve (AUC)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "AUC_score = roc_auc_score(testing_dataset_labels, prediction)\n",
    "\n",
    "# J.3. To Plot the ROC Curve with AUC\n",
    "\n",
    "plt.plot(FPR, TPR, label = \"ROC Curve\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a884d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# J.4. For the Plot of Baseline for AUC\n",
    "\n",
    "plt.plot(np.linspace(0, 1, 10), np.linspace(0, 1, 10), label='Baseline', linestyle='--')\n",
    "plt.title(f'ROC Curve with AUC = {round(AUC_score,4)} for the Convolutional Neural Network Model')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.legend();\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d79010c",
   "metadata": {},
   "source": [
    "# REPEATING PART 6 B: PERFORM CROSS VALIDATION TO ASSESS THE CNN MODEL'S PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f870fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner import RandomSearch, Hyperband\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Ftrl\n",
    "\n",
    "# Define the model for hyperparameter tuning\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=32), kernel_size=hp.Choice('conv_1_kernel', values=[3, 5]), activation='relu', input_shape=(128, 128, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=hp.Int('conv_2_filter', min_value=32, max_value=128, step=32), kernel_size=hp.Choice('conv_2_kernel', values=[3, 5]), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=hp.Int('conv_3_filter', min_value=64, max_value=256, step=64), kernel_size=hp.Choice('conv_3_kernel', values=[3, 5]), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv2D(filters=hp.Int('conv_4_filter', min_value=64, max_value=256, step=64), kernel_size=hp.Choice('conv_4_kernel', values=[3, 5]), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=hp.Int('dense_1_units', min_value=128, max_value=512, step=64), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('dense_2_units', min_value=64, max_value=256, step=64), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[0.001, 0.0001, 0.00001])), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy','mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bb27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model1 = KerasClassifier(build_fn=create_model, epochs=10, batch_size=16, verbose=1)\n",
    "k_fold = StratifiedKFold(n_splits = 2, shuffle = True, random_state=42)\n",
    " \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Assuming you have already loaded the train_data DataFrame\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for idx, row in train_data.iterrows():\n",
    "    img_path = row['images']\n",
    "    label = row['labels']\n",
    "    img = load_img(img_path, target_size=(128, 128))  # Specify the desired image size\n",
    "    img_array = img_to_array(img) / 255.0  # Normalize the pixel values to [0, 1]\n",
    "    train_images.append(img_array)\n",
    "    if label == \"Fire\":\n",
    "        train_labels.append(0)\n",
    "    else:\n",
    "        train_labels.append(1)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8661e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f68df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Accuracy as Scoring Metric for Cross-Validation\n",
    "accuracy = cross_val_score(estimator=best_model1, X=train_images, y=train_labels, cv=k_fold, scoring=\"accuracy\", n_jobs=1, error_score='raise')\n",
    "accuracy_average = accuracy.mean()\n",
    "accuracy_standard_deviation = accuracy.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d332e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ACCURACY OF K-FOLDS:\")\n",
    "print(accuracy)\n",
    "print('')\n",
    "print(\"AVERAGE ACCURACY OF K-FOLDS:\")\n",
    "print(accuracy_average)\n",
    "print('')\n",
    "print(\"ACCURACY DEVIATION OF K-FOLDS:\")\n",
    "print(accuracy_standard_deviation)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44a93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Precision as Scoring Metric for Cross-Validation\n",
    "precision_scorer = make_scorer(precision_score, average='weighted')\n",
    "precision = cross_val_score(estimator=best_model1, X=train_images, y=train_labels, cv=k_fold, scoring=precision_scorer, n_jobs=1, error_score='raise')\n",
    "precision_average = precision.mean()\n",
    "precision_standard_deviation = precision.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83861d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PRECISION OF K-FOLDS:\")\n",
    "print(precision)\n",
    "print('')\n",
    "print(\"AVERAGE PRECISION OF K-FOLDS:\")\n",
    "print(precision_average)\n",
    "print('')\n",
    "print(\"PRECISION DEVIATION OF K-FOLDS:\")\n",
    "print(precision_standard_deviation)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b23273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Recall as Scoring Metric for Cross-Validation\n",
    "recall_scorer = make_scorer(recall_score, average='weighted')\n",
    "recall = cross_val_score(estimator=best_model1, X=train_images, y=train_labels, cv=k_fold, scoring=recall_scorer, n_jobs=1, error_score='raise')\n",
    "recall_average = recall.mean()\n",
    "recall_standard_deviation = recall.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a478248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RECALL OF K-FOLDS:\")\n",
    "print(recall)\n",
    "print('')\n",
    "print(\"AVERAGE RECALL OF K-FOLDS:\")\n",
    "print(recall_average)\n",
    "print('')\n",
    "print(\"RECALL DEVIATION OF K-FOLDS:\")\n",
    "print(recall_standard_deviation)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using F1-Score as Scoring Metric for Cross-Validation\n",
    "f1_scorer = make_scorer(f1_score, average='weighted')\n",
    "f1 = cross_val_score(estimator=best_model1, X=train_images, y=train_labels, cv=k_fold, scoring=f1_scorer, n_jobs=1, error_score='raise')\n",
    "f1_average = f1.mean()\n",
    "f1_standard_deviation = f1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca01ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"F1 SCORE OF K-FOLDS:\")\n",
    "print(f1)\n",
    "print('')\n",
    "print(\"AVERAGE F1 SCORE OF K-FOLDS:\")\n",
    "print(f1_average)\n",
    "print('')\n",
    "print(\"F1 SCORE DEVIATION OF K-FOLDS:\")\n",
    "print(f1_standard_deviation)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ROC AUC as Scoring Metric for Cross-Validation (binary classification)\n",
    "roc_auc_scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "roc_auc = cross_val_score(estimator=best_model1, X=train_images, y=train_labels, cv=k_fold, scoring=roc_auc_scorer, n_jobs=1, error_score='raise')\n",
    "roc_auc_average = roc_auc.mean()\n",
    "roc_auc_standard_deviation = roc_auc.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC AUC SCORE OF K-FOLDS:\")\n",
    "print(roc_auc)\n",
    "print('')\n",
    "print(\"AVERAGE ROC AUC SCORE OF K-FOLDS:\")\n",
    "print(roc_auc_average)\n",
    "print('')\n",
    "print(\"ROC AUC SCORE DEVIATION OF K-FOLDS:\")\n",
    "print(roc_auc_standard_deviation)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be06b3",
   "metadata": {},
   "source": [
    "# REPEATING PART 7: MAKING SINGLE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e69878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Keras Libraries and Packages\n",
    "\n",
    "from keras.utils import load_img\n",
    "from keras.utils import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30971ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. To Load the Trained Model\n",
    "\n",
    "from keras.models import load_model\n",
    "classifier = load_model(\"CNN_BEST_MODEL.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d683129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. For the First Single Image\n",
    "\n",
    "test_image = load_img(\"dataset/single_prediction/fire_test.jpg\", target_size = (128, 128))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "prediction = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if prediction[0][0] == 1:\n",
    "    prediction = 'Non-Fire'      \n",
    "else: \n",
    "    prediction = 'Fire'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. For the Second Single Image\n",
    "\n",
    "test_image = load_img(\"dataset/single_prediction/non_test.jpg\", target_size = (128, 128))\n",
    "test_image = img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "prediction = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if prediction[0][0] == 1:\n",
    "    prediction = 'Non-Fire'   \n",
    "else: \n",
    "    prediction = 'Fire'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039e11c5",
   "metadata": {},
   "source": [
    "\n",
    "<b>SUBMITTED BY GROUP 11:\n",
    "\n",
    "    Berbon, Benedict B.\n",
    "    Panaligan Maria Carmela L.\n",
    "    Sunga, Jullianne Christille N.\n",
    "\n",
    "<b>SUBMITTED TO:\n",
    "\n",
    "    DR. ROBERT G. DE LUNA, PECE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a1df66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
